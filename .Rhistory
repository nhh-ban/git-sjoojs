# -------------------------------------------
# More detailed steps to complete Problem 1.
library(tidyverse)    # Contains most of what we need.
# Read the entire data file into memory using the readLines()-function. Use the
# URL direcly or read the data from the local file that is in the repository.
# The readLines()-function puts each line into a separate element in a character
# vector. Looking at ?readLines it seems that we only need to provide one
# argument: the "connection", or in other words the location of the text file.
# Replace the "?" below with the location of the file. We do get a warning that
# the file does not end with an "end of line"-character (EOL). This does not
# seem to pose a problem later, and it seems that we can silece the warning by
# switchin off the "warn"-argument. Do that if you wish.
raw_file <- readLines(con = "http://www.sao.ru/lv/lvgdb/article/suites_dw_Table1.txt")
# Identify the line number L of the separator line between the column names and
# the rest of the data table.
raw_file # Line number 15
# Now every line in the file is in its separate element in the character vector
# "raw_file". The next key step is to identify which line contains the separator
# line between the column names and the rest of the table. We have to come up
# with a rule that defines this line. Let us for example say that "L is the
# first line in the data file that starts with '--'". We can extract the first
# two letters of each of the elements in the "raw_data" vector using the
# substr()-function.
# What do you need to replace the two question marks with in order to extract
# the first two letters?
substr(x = raw_file, start = 1, stop = 2)
# The next step is then to find out *which* line starts with "--", and pick out
# the first one. This can be done in a nice little pipe, where you have to fill
# out the question marks and the missing function names:
L <-
(substr(x = raw_file, start = 1, stop = 2) == "--") %>%
which() %>%
min()
# Save the variable descriptions (i.e. the information in lines 1:(L-2)) in a
# text-file for future reference using the cat()-function. The first argument is
# the information that we want to print out. In order to get each element in the
# "raw_file"-vector on a separate line we also provide the sep-argument, where
# we put the "end-of-line"-character "\n". We also need to come up with a file
# name. Replace the question marks:
cat(raw_file[1:(L-2)], sep = "\n", file = "Variable descriptions Problem 2")
# Extract the variable names (i.e. line (L-1)), store the names in a vector.
vector_names <- raw_file[1:(L-1)]
# This is a little bit dirty. We want to *split* the string in raw_data[L-1]
# *by* the character "|", and then we want to *trim* away all the leading and
# trailing white spaces. The first step can be accomplished using the
# str_split()-function in the stringr-package (this is already loaded through
# tidyverse), but there is a delicate detail here. The "|"-character has special
# meaning in R ("or"), so it must be *escaped*, meaning that we tell R that it
# should be interpreted as a normal character. We do that by adding two forward
# slashes in front of it. This function returns a list, with one element for
# each input element. We only send one string in, and hence get only one list
# element out (check that!). We just unlist it to get out the vector. Then we
# apply the str_trim()-function (also in the stringr-package) to get rid of all
# the empty space. Replace the question mark below:
variable_names <-
str_split(string = raw_file[L-1], pattern = "\\|") %>%
unlist() %>%
str_trim()
# Read the data. One way to do this is to rewrite the data to a new .csv-file
# with comma-separators for instance using cat() again, with the variable names
# from the step above on the first line (see for instance paste() for collapsing
# that vector to a single string with commas as separators).
# Let us try the approach described above. It is quite transparent, but could
# probably be done quicker. We take the elements in "raw_file" containing data,
# replace all "|" with "," and remove all empty space. The gsub-function is
# super for this kind of search-and-replace. Replace the question mark below.
comma_separated_values <-
raw_file[(L+1):length(raw_file)] %>%
gsub("\\|", ",", .) %>%
gsub(" ", "", .)
# We then just add the variable names (separated with commas) on top, and
# cat()-the whole ting to a .csv-file in the same way as we did with the
# variable descriptions above.
comma_separated_values_with_names <-
c(paste(variable_names, collapse = ","),
comma_separated_values)
# Replace the question mark and come up with a file name
cat(comma_separated_values_with_names, sep = "\n", file = "formatted_galaxies.csv")
# Read the file back in as a normal csv-file. The readr-package is part of
# tidyverse, so it is already loaded.
galaxies <- read_csv("formatted_galaxies.csv")
# You should now have a nice, clean data frame with galaxies and their
# characteristics in memory. As of March 2022 it should contain 796
# observations.
# PROBLEM 3
library(ggplot2)
library(tidyverse)
# Calculate mean and standard deviation for a_26, log_m26, m_b, and log_lk
mean_a26 <- mean(galaxies$a_26, na.rm = TRUE)
sd_a26 <- sd(galaxies$a_26, na.rm = TRUE)
mean_log_m26 <- mean(galaxies$log_m26, na.rm = TRUE)
sd_log_m26 <- sd(galaxies$log_m26, na.rm = TRUE)
mean_mb <- mean(galaxies$m_b, na.rm = TRUE)
sd_mb <- sd(galaxies$m_b, na.rm = TRUE)
mean_log_lk <- mean(galaxies$log_lk, na.rm = TRUE)
sd_log_lk <- sd(galaxies$log_lk, na.rm = TRUE)
# Plotting the distributions with overlaid normal distribution curves
normal_dist <- ggplot(galaxies) +
# a_26 distribution
# geom_density(aes(x=a_26, y=..density.., fill="Linear Diameter (a_26)"), alpha=0.5) +
# stat_function(fun=dnorm, args=list(mean=mean_a26, sd=sd_a26), color="darkblue", linetype="dashed") +
# log_m26 distribution
#geom_density(aes(x=log_m26, y=..density.., fill="Log Mass (log_m26)"), alpha=0.5) +
# stat_function(fun=dnorm, args=list(mean=mean_log_m26, sd=sd_log_m26), color="darkred", linetype="dashed") +
# m_b distribution
geom_density(aes(x=m_b, y=..density.., fill="Magnitude (m_b)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_mb, sd=sd_mb), color="darkgreen", linetype="dashed") +
# log_lk distribution
geom_density(aes(x=log_lk, y=..density.., fill="Log Stellar Mass (log_lk)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_lk, sd=sd_log_lk), color="darkorange", linetype="dashed") +
theme_minimal() +
labs(title="Density Plots with Normal Distribution Curves", x="Value", y="Density") +
scale_fill_manual(values=c("blue", "red", "green", "orange"))+
coord_cartesian(xlim=c(0, 20)) # setting desired range
normal_dist
# Skeleton file 2 for Assignment 1 in BAN400.
# -------------------------------------------
# More detailed steps to complete Problem 1.
library(tidyverse)    # Contains most of what we need.
# Read the entire data file into memory using the readLines()-function. Use the
# URL direcly or read the data from the local file that is in the repository.
# The readLines()-function puts each line into a separate element in a character
# vector. Looking at ?readLines it seems that we only need to provide one
# argument: the "connection", or in other words the location of the text file.
# Replace the "?" below with the location of the file. We do get a warning that
# the file does not end with an "end of line"-character (EOL). This does not
# seem to pose a problem later, and it seems that we can silece the warning by
# switchin off the "warn"-argument. Do that if you wish.
raw_file <- readLines(con = "http://www.sao.ru/lv/lvgdb/article/suites_dw_Table1.txt")
# Identify the line number L of the separator line between the column names and
# the rest of the data table.
raw_file # Line number 15
# Now every line in the file is in its separate element in the character vector
# "raw_file". The next key step is to identify which line contains the separator
# line between the column names and the rest of the table. We have to come up
# with a rule that defines this line. Let us for example say that "L is the
# first line in the data file that starts with '--'". We can extract the first
# two letters of each of the elements in the "raw_data" vector using the
# substr()-function.
# What do you need to replace the two question marks with in order to extract
# the first two letters?
substr(x = raw_file, start = 1, stop = 2)
# The next step is then to find out *which* line starts with "--", and pick out
# the first one. This can be done in a nice little pipe, where you have to fill
# out the question marks and the missing function names:
L <-
(substr(x = raw_file, start = 1, stop = 2) == "--") %>%
which() %>%
min()
# Save the variable descriptions (i.e. the information in lines 1:(L-2)) in a
# text-file for future reference using the cat()-function. The first argument is
# the information that we want to print out. In order to get each element in the
# "raw_file"-vector on a separate line we also provide the sep-argument, where
# we put the "end-of-line"-character "\n". We also need to come up with a file
# name. Replace the question marks:
cat(raw_file[1:(L-2)], sep = "\n", file = "Variable descriptions Problem 2")
# Extract the variable names (i.e. line (L-1)), store the names in a vector.
vector_names <- raw_file[1:(L-1)]
# This is a little bit dirty. We want to *split* the string in raw_data[L-1]
# *by* the character "|", and then we want to *trim* away all the leading and
# trailing white spaces. The first step can be accomplished using the
# str_split()-function in the stringr-package (this is already loaded through
# tidyverse), but there is a delicate detail here. The "|"-character has special
# meaning in R ("or"), so it must be *escaped*, meaning that we tell R that it
# should be interpreted as a normal character. We do that by adding two forward
# slashes in front of it. This function returns a list, with one element for
# each input element. We only send one string in, and hence get only one list
# element out (check that!). We just unlist it to get out the vector. Then we
# apply the str_trim()-function (also in the stringr-package) to get rid of all
# the empty space. Replace the question mark below:
variable_names <-
str_split(string = raw_file[L-1], pattern = "\\|") %>%
unlist() %>%
str_trim()
# Read the data. One way to do this is to rewrite the data to a new .csv-file
# with comma-separators for instance using cat() again, with the variable names
# from the step above on the first line (see for instance paste() for collapsing
# that vector to a single string with commas as separators).
# Let us try the approach described above. It is quite transparent, but could
# probably be done quicker. We take the elements in "raw_file" containing data,
# replace all "|" with "," and remove all empty space. The gsub-function is
# super for this kind of search-and-replace. Replace the question mark below.
comma_separated_values <-
raw_file[(L+1):length(raw_file)] %>%
gsub("\\|", ",", .) %>%
gsub(" ", "", .)
# We then just add the variable names (separated with commas) on top, and
# cat()-the whole ting to a .csv-file in the same way as we did with the
# variable descriptions above.
comma_separated_values_with_names <-
c(paste(variable_names, collapse = ","),
comma_separated_values)
# Replace the question mark and come up with a file name
cat(comma_separated_values_with_names, sep = "\n", file = "formatted_galaxies.csv")
# Read the file back in as a normal csv-file. The readr-package is part of
# tidyverse, so it is already loaded.
galaxies <- read_csv("formatted_galaxies.csv")
# You should now have a nice, clean data frame with galaxies and their
# characteristics in memory. As of March 2022 it should contain 796
# observations.
# PROBLEM 3
library(ggplot2)
library(tidyverse)
# Calculate mean and standard deviation for a_26, log_m26, m_b, and log_lk
mean_a26 <- mean(galaxies$a_26, na.rm = TRUE)
sd_a26 <- sd(galaxies$a_26, na.rm = TRUE)
mean_log_m26 <- mean(galaxies$log_m26, na.rm = TRUE)
sd_log_m26 <- sd(galaxies$log_m26, na.rm = TRUE)
mean_mb <- mean(galaxies$m_b, na.rm = TRUE)
sd_mb <- sd(galaxies$m_b, na.rm = TRUE)
mean_log_lk <- mean(galaxies$log_lk, na.rm = TRUE)
sd_log_lk <- sd(galaxies$log_lk, na.rm = TRUE)
# Plotting the distributions with overlaid normal distribution curves
normal_dist <- ggplot(galaxies) +
# a_26 distribution
# geom_density(aes(x=a_26, y=..density.., fill="Linear Diameter (a_26)"), alpha=0.5) +
# stat_function(fun=dnorm, args=list(mean=mean_a26, sd=sd_a26), color="darkblue", linetype="dashed") +
# log_m26 distribution
geom_density(aes(x=log_m26, y=..density.., fill="Log Mass (log_m26)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_m26, sd=sd_log_m26), color="darkred", linetype="dashed") +
# m_b distribution
geom_density(aes(x=m_b, y=..density.., fill="Magnitude (m_b)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_mb, sd=sd_mb), color="darkgreen", linetype="dashed") +
# log_lk distribution
geom_density(aes(x=log_lk, y=..density.., fill="Log Stellar Mass (log_lk)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_lk, sd=sd_log_lk), color="darkorange", linetype="dashed") +
theme_minimal() +
labs(title="Density Plots with Normal Distribution Curves", x="Value", y="Density") +
scale_fill_manual(values=c("blue", "red", "green", "orange"))+
coord_cartesian(xlim=c(0, 20)) # setting desired range
normal_dist
# Skeleton file 2 for Assignment 1 in BAN400.
# -------------------------------------------
# More detailed steps to complete Problem 1.
library(tidyverse)    # Contains most of what we need.
# Read the entire data file into memory using the readLines()-function. Use the
# URL direcly or read the data from the local file that is in the repository.
# The readLines()-function puts each line into a separate element in a character
# vector. Looking at ?readLines it seems that we only need to provide one
# argument: the "connection", or in other words the location of the text file.
# Replace the "?" below with the location of the file. We do get a warning that
# the file does not end with an "end of line"-character (EOL). This does not
# seem to pose a problem later, and it seems that we can silece the warning by
# switchin off the "warn"-argument. Do that if you wish.
raw_file <- readLines(con = "http://www.sao.ru/lv/lvgdb/article/suites_dw_Table1.txt")
# Identify the line number L of the separator line between the column names and
# the rest of the data table.
raw_file # Line number 15
# Now every line in the file is in its separate element in the character vector
# "raw_file". The next key step is to identify which line contains the separator
# line between the column names and the rest of the table. We have to come up
# with a rule that defines this line. Let us for example say that "L is the
# first line in the data file that starts with '--'". We can extract the first
# two letters of each of the elements in the "raw_data" vector using the
# substr()-function.
# What do you need to replace the two question marks with in order to extract
# the first two letters?
substr(x = raw_file, start = 1, stop = 2)
# The next step is then to find out *which* line starts with "--", and pick out
# the first one. This can be done in a nice little pipe, where you have to fill
# out the question marks and the missing function names:
L <-
(substr(x = raw_file, start = 1, stop = 2) == "--") %>%
which() %>%
min()
# Save the variable descriptions (i.e. the information in lines 1:(L-2)) in a
# text-file for future reference using the cat()-function. The first argument is
# the information that we want to print out. In order to get each element in the
# "raw_file"-vector on a separate line we also provide the sep-argument, where
# we put the "end-of-line"-character "\n". We also need to come up with a file
# name. Replace the question marks:
cat(raw_file[1:(L-2)], sep = "\n", file = "Variable descriptions Problem 2")
# Extract the variable names (i.e. line (L-1)), store the names in a vector.
vector_names <- raw_file[1:(L-1)]
# This is a little bit dirty. We want to *split* the string in raw_data[L-1]
# *by* the character "|", and then we want to *trim* away all the leading and
# trailing white spaces. The first step can be accomplished using the
# str_split()-function in the stringr-package (this is already loaded through
# tidyverse), but there is a delicate detail here. The "|"-character has special
# meaning in R ("or"), so it must be *escaped*, meaning that we tell R that it
# should be interpreted as a normal character. We do that by adding two forward
# slashes in front of it. This function returns a list, with one element for
# each input element. We only send one string in, and hence get only one list
# element out (check that!). We just unlist it to get out the vector. Then we
# apply the str_trim()-function (also in the stringr-package) to get rid of all
# the empty space. Replace the question mark below:
variable_names <-
str_split(string = raw_file[L-1], pattern = "\\|") %>%
unlist() %>%
str_trim()
# Read the data. One way to do this is to rewrite the data to a new .csv-file
# with comma-separators for instance using cat() again, with the variable names
# from the step above on the first line (see for instance paste() for collapsing
# that vector to a single string with commas as separators).
# Let us try the approach described above. It is quite transparent, but could
# probably be done quicker. We take the elements in "raw_file" containing data,
# replace all "|" with "," and remove all empty space. The gsub-function is
# super for this kind of search-and-replace. Replace the question mark below.
comma_separated_values <-
raw_file[(L+1):length(raw_file)] %>%
gsub("\\|", ",", .) %>%
gsub(" ", "", .)
# We then just add the variable names (separated with commas) on top, and
# cat()-the whole ting to a .csv-file in the same way as we did with the
# variable descriptions above.
comma_separated_values_with_names <-
c(paste(variable_names, collapse = ","),
comma_separated_values)
# Replace the question mark and come up with a file name
cat(comma_separated_values_with_names, sep = "\n", file = "formatted_galaxies.csv")
# Read the file back in as a normal csv-file. The readr-package is part of
# tidyverse, so it is already loaded.
galaxies <- read_csv("formatted_galaxies.csv")
# You should now have a nice, clean data frame with galaxies and their
# characteristics in memory. As of March 2022 it should contain 796
# observations.
# PROBLEM 3
library(ggplot2)
library(tidyverse)
# Calculate mean and standard deviation for a_26, log_m26, m_b, and log_lk
mean_a26 <- mean(galaxies$a_26, na.rm = TRUE)
sd_a26 <- sd(galaxies$a_26, na.rm = TRUE)
mean_log_m26 <- mean(galaxies$log_m26, na.rm = TRUE)
sd_log_m26 <- sd(galaxies$log_m26, na.rm = TRUE)
mean_mb <- mean(galaxies$m_b, na.rm = TRUE)
sd_mb <- sd(galaxies$m_b, na.rm = TRUE)
mean_log_lk <- mean(galaxies$log_lk, na.rm = TRUE)
sd_log_lk <- sd(galaxies$log_lk, na.rm = TRUE)
# Plotting the distributions with overlaid normal distribution curves
normal_dist <- ggplot(galaxies) +
# a_26 distribution
geom_density(aes(x=a_26, y=..density.., fill="Linear Diameter (a_26)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_a26, sd=sd_a26), color="darkblue", linetype="dashed") +
# log_m26 distribution
geom_density(aes(x=log_m26, y=..density.., fill="Log Mass (log_m26)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_m26, sd=sd_log_m26), color="darkred", linetype="dashed") +
# m_b distribution
geom_density(aes(x=m_b, y=..density.., fill="Magnitude (m_b)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_mb, sd=sd_mb), color="darkgreen", linetype="dashed") +
# log_lk distribution
geom_density(aes(x=log_lk, y=..density.., fill="Log Stellar Mass (log_lk)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_lk, sd=sd_log_lk), color="darkorange", linetype="dashed") +
theme_minimal() +
labs(title="Density Plots with Normal Distribution Curves", x="Value", y="Density") +
scale_fill_manual(values=c("blue", "red", "green", "orange"))+
coord_cartesian(xlim=c(0, 20)) # setting desired range
normal_dist
# Skeleton file 2 for Assignment 1 in BAN400.
# -------------------------------------------
# More detailed steps to complete Problem 1.
library(tidyverse)    # Contains most of what we need.
# Read the entire data file into memory using the readLines()-function. Use the
# URL direcly or read the data from the local file that is in the repository.
# The readLines()-function puts each line into a separate element in a character
# vector. Looking at ?readLines it seems that we only need to provide one
# argument: the "connection", or in other words the location of the text file.
# Replace the "?" below with the location of the file. We do get a warning that
# the file does not end with an "end of line"-character (EOL). This does not
# seem to pose a problem later, and it seems that we can silece the warning by
# switchin off the "warn"-argument. Do that if you wish.
raw_file <- readLines(con = "http://www.sao.ru/lv/lvgdb/article/suites_dw_Table1.txt")
# Identify the line number L of the separator line between the column names and
# the rest of the data table.
raw_file # Line number 15
# Now every line in the file is in its separate element in the character vector
# "raw_file". The next key step is to identify which line contains the separator
# line between the column names and the rest of the table. We have to come up
# with a rule that defines this line. Let us for example say that "L is the
# first line in the data file that starts with '--'". We can extract the first
# two letters of each of the elements in the "raw_data" vector using the
# substr()-function.
# What do you need to replace the two question marks with in order to extract
# the first two letters?
substr(x = raw_file, start = 1, stop = 2)
# The next step is then to find out *which* line starts with "--", and pick out
# the first one. This can be done in a nice little pipe, where you have to fill
# out the question marks and the missing function names:
L <-
(substr(x = raw_file, start = 1, stop = 2) == "--") %>%
which() %>%
min()
# Save the variable descriptions (i.e. the information in lines 1:(L-2)) in a
# text-file for future reference using the cat()-function. The first argument is
# the information that we want to print out. In order to get each element in the
# "raw_file"-vector on a separate line we also provide the sep-argument, where
# we put the "end-of-line"-character "\n". We also need to come up with a file
# name. Replace the question marks:
cat(raw_file[1:(L-2)], sep = "\n", file = "Variable descriptions Problem 2")
# Extract the variable names (i.e. line (L-1)), store the names in a vector.
vector_names <- raw_file[1:(L-1)]
# This is a little bit dirty. We want to *split* the string in raw_data[L-1]
# *by* the character "|", and then we want to *trim* away all the leading and
# trailing white spaces. The first step can be accomplished using the
# str_split()-function in the stringr-package (this is already loaded through
# tidyverse), but there is a delicate detail here. The "|"-character has special
# meaning in R ("or"), so it must be *escaped*, meaning that we tell R that it
# should be interpreted as a normal character. We do that by adding two forward
# slashes in front of it. This function returns a list, with one element for
# each input element. We only send one string in, and hence get only one list
# element out (check that!). We just unlist it to get out the vector. Then we
# apply the str_trim()-function (also in the stringr-package) to get rid of all
# the empty space. Replace the question mark below:
variable_names <-
str_split(string = raw_file[L-1], pattern = "\\|") %>%
unlist() %>%
str_trim()
# Read the data. One way to do this is to rewrite the data to a new .csv-file
# with comma-separators for instance using cat() again, with the variable names
# from the step above on the first line (see for instance paste() for collapsing
# that vector to a single string with commas as separators).
# Let us try the approach described above. It is quite transparent, but could
# probably be done quicker. We take the elements in "raw_file" containing data,
# replace all "|" with "," and remove all empty space. The gsub-function is
# super for this kind of search-and-replace. Replace the question mark below.
comma_separated_values <-
raw_file[(L+1):length(raw_file)] %>%
gsub("\\|", ",", .) %>%
gsub(" ", "", .)
# We then just add the variable names (separated with commas) on top, and
# cat()-the whole ting to a .csv-file in the same way as we did with the
# variable descriptions above.
comma_separated_values_with_names <-
c(paste(variable_names, collapse = ","),
comma_separated_values)
# Replace the question mark and come up with a file name
cat(comma_separated_values_with_names, sep = "\n", file = "formatted_galaxies.csv")
# Read the file back in as a normal csv-file. The readr-package is part of
# tidyverse, so it is already loaded.
galaxies <- read_csv("formatted_galaxies.csv")
# You should now have a nice, clean data frame with galaxies and their
# characteristics in memory. As of March 2022 it should contain 796
# observations.
# PROBLEM 3
library(ggplot2)
library(tidyverse)
# Calculate mean and standard deviation for a_26, log_m26, m_b, and log_lk
mean_a26 <- mean(galaxies$a_26, na.rm = TRUE)
sd_a26 <- sd(galaxies$a_26, na.rm = TRUE)
mean_log_m26 <- mean(galaxies$log_m26, na.rm = TRUE)
sd_log_m26 <- sd(galaxies$log_m26, na.rm = TRUE)
mean_mb <- mean(galaxies$m_b, na.rm = TRUE)
sd_mb <- sd(galaxies$m_b, na.rm = TRUE)
mean_log_lk <- mean(galaxies$log_lk, na.rm = TRUE)
sd_log_lk <- sd(galaxies$log_lk, na.rm = TRUE)
# Plotting the distributions with overlaid normal distribution curves
normal_dist <- ggplot(galaxies) +
# a_26 distribution
geom_density(aes(x=a_26, y=..density.., fill="Linear Diameter (a_26)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_a26, sd=sd_a26), color="darkblue", linetype="dashed") +
# log_m26 distribution
geom_density(aes(x=log_m26, y=..density.., fill="Log Mass (log_m26)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_m26, sd=sd_log_m26), color="darkred", linetype="dashed") +
# m_b distribution
#geom_density(aes(x=m_b, y=..density.., fill="Magnitude (m_b)"), alpha=0.5) +
#stat_function(fun=dnorm, args=list(mean=mean_mb, sd=sd_mb), color="darkgreen", linetype="dashed") +
# log_lk distribution
geom_density(aes(x=log_lk, y=..density.., fill="Log Stellar Mass (log_lk)"), alpha=0.5) +
stat_function(fun=dnorm, args=list(mean=mean_log_lk, sd=sd_log_lk), color="darkorange", linetype="dashed") +
theme_minimal() +
labs(title="Density Plots with Normal Distribution Curves", x="Value", y="Density") +
scale_fill_manual(values=c("blue", "red", "green", "orange"))+
coord_cartesian(xlim=c(0, 20)) # setting desired range
normal_dist
# Reading the data file
library(tidyverse)
library(ggplot2)
raw_file1 <- readLines(con = "https://www.sao.ru/lv/lvgdb/article/UCNG_Table4.txt")
L1 <- # Reading it back, want to remove line 2
(substr(x = raw_file1, start = 1, stop = 2) == "--") %>%
which() %>%
min()
column_headings <-
str_split(string = raw_file1[L1-1], pattern = "\\|") %>%
unlist() %>%
str_trim() # Pulling out column headings
comma_separated_values1 <-
raw_file1[(L1+1):length(raw_file1)] %>%
gsub("\\|", ",", .) %>%
gsub(" ", "", .) # Getting the rest of the data
comma_separated_values_with_names1 <- # Putting it all together
c(paste(column_headings, collapse = ","),
comma_separated_values1)
# Saving
cat(comma_separated_values_with_names1, sep = "\n",
file = "formatted_galaxies1.csv")
galaxies1 <- read_csv("formatted_galaxies1.csv")
# Removing unwanted columns
trimmed_gal1 <- galaxies1 %>%
transmute(Name = name, Velocity = cz)
trimmed_gal <- galaxies %>%
transmute(Name = name, Distance = D)
# joining
final <- trimmed_gal %>% inner_join(trimmed_gal1)
# plot for task 1
ggplot(final, aes(x = Distance, y = Velocity)) +
geom_point() +  # Add points
labs(
title = "Scatterplot of Distance vs. Velocity",
x = "Distance",
y = "Velocity"
) +
theme_minimal() # We see that the farther away the galaxies are, the higher
# is their velocity in general. So yeah, I agree
# the Hubble's constant for task 2
final %>% mutate(Hubble = Velocity/Distance) %>% arrange(Name)
# the Hubble's constant for task 2
final %>% mutate(Hubble = Velocity/Distance) %>% arrange(Name)
# the Hubble's constant for task 2
final <- final %>% mutate(Hubble = Velocity/Distance) %>% arrange(Name)
final
final %>% mean(Hubble)
final %>% summarise(Hubble = mean(Hubble))
